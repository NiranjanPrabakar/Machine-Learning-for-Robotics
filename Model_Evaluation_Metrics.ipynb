{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiranjanPrabakar/Machine-Learning-for-Robotics/blob/main/Model_Evaluation_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkaB1ZWkE7T",
        "outputId": "2d14ee5d-d4b1-463e-c4f8-a0f3d33db491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Training models...\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Evaluating models...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "\n",
            "LSTM:\n",
            "  MAE: 243.7302\n",
            "  MSE: 104454.1723\n",
            "  RMSE: 323.1937\n",
            "  R²: -2.4082\n",
            "\n",
            "Random Forest:\n",
            "  MAE: 141.6161\n",
            "  MSE: 34619.6983\n",
            "  RMSE: 186.0637\n",
            "  R²: -0.1296\n",
            "\n",
            "Gradient Boosting:\n",
            "  MAE: 152.5883\n",
            "  MSE: 38715.7670\n",
            "  RMSE: 196.7632\n",
            "  R²: -0.2632\n",
            "\n",
            "XGBoost:\n",
            "  MAE: 181.5959\n",
            "  MSE: 53556.9000\n",
            "  RMSE: 231.4236\n",
            "  R²: -0.7475\n",
            "\n",
            "LSTM + RF:\n",
            "  MAE: 148.1449\n",
            "  MSE: 37025.0415\n",
            "  RMSE: 192.4189\n",
            "  R²: -0.2081\n",
            "\n",
            "LSTM + XGBoost:\n",
            "  MAE: 180.2928\n",
            "  MSE: 53444.1157\n",
            "  RMSE: 231.1798\n",
            "  R²: -0.7438\n",
            "\n",
            "Best model based on RMSE: Random Forest\n",
            "\n",
            "Forecasting future rainfall (2016-2030)...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "Future Rainfall Predictions (2016-2030):\n",
            "    YEAR  Random Forest  Gradient Boosting  LSTM + RF  LSTM + XGBoost\n",
            "0   2016        979.128         860.434066    991.240      917.911072\n",
            "1   2017        993.816         950.459900    982.297      951.697205\n",
            "2   2018        994.044         987.768842    986.080     1039.657837\n",
            "3   2019        960.467         951.051478    970.470      935.388489\n",
            "4   2020       1005.567         950.283763   1009.042     1002.234375\n",
            "5   2021        987.568         944.819471    990.877      972.873657\n",
            "6   2022        986.065         943.386152    987.085      973.383301\n",
            "7   2023        984.240         942.040134    988.837      954.208435\n",
            "8   2024        982.302         945.156691    987.994      973.181946\n",
            "9   2025        985.862         945.156691    990.804      974.466370\n",
            "10  2026        983.679         945.156691    988.835      972.894470\n",
            "11  2027        984.426         945.156691    989.690      972.894470\n",
            "12  2028        983.114         945.156691    988.390      973.238281\n",
            "13  2029        982.889         945.156691    989.229      973.238281\n",
            "14  2030        983.024         945.156691    989.229      973.238281\n",
            "\n",
            "Visualizing results...\n",
            "\n",
            "Analysis complete! Check the generated visualizations for insights.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Load the data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Filter the data for TAMIL NADU only\n",
        "    tamil_nadu_data = df[df['SUBDIVISION'] == 'TAMIL NADU']\n",
        "\n",
        "    # Drop rows with null values\n",
        "    tamil_nadu_data = tamil_nadu_data.dropna()\n",
        "\n",
        "    # Reset index\n",
        "    tamil_nadu_data = tamil_nadu_data.reset_index(drop=True)\n",
        "\n",
        "    # Create a new dataframe with YEAR and monthly data\n",
        "    months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
        "\n",
        "    # Calculate the average monthly rainfall\n",
        "    monthly_rainfall = tamil_nadu_data[['YEAR'] + months]\n",
        "\n",
        "    # Create a time series dataframe\n",
        "    time_series_data = monthly_rainfall.copy()\n",
        "\n",
        "    # Add annual rainfall as target\n",
        "    time_series_data['ANNUAL'] = tamil_nadu_data['ANNUAL']\n",
        "\n",
        "    return time_series_datadata\n",
        "\n",
        "# 2. Prepare data for time series forecasting\n",
        "def prepare_time_series_data(data, n_steps=5):\n",
        "    # Create sequences for LSTM\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps):\n",
        "        # Create sequence of n_steps years' monthly data\n",
        "        sequence = data.iloc[i:i+n_steps, 1:13].values.flatten()\n",
        "        X.append(sequence)\n",
        "        # Use the annual rainfall of the next year as target\n",
        "        y.append(data.iloc[i+n_steps, -1])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 3. Create and train LSTM model\n",
        "def create_lstm_model(X_train):\n",
        "    # Reshape input for LSTM [samples, timesteps, features]\n",
        "    n_samples = X_train.shape[0]\n",
        "    n_steps = 5\n",
        "    n_features = 12  # 12 months\n",
        "    X_train_reshaped = X_train.reshape(n_samples, n_steps, n_features)\n",
        "\n",
        "    # Create LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features), return_sequences=True))\n",
        "    model.add(LSTM(50, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model, X_train_reshaped\n",
        "\n",
        "# 4. Create and train hybrid models and baseline models\n",
        "def train_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    # LSTM model\n",
        "    lstm_model, X_train_reshaped = create_lstm_model(X_train)\n",
        "    X_val_reshaped = X_val.reshape(X_val.shape[0], 5, 12)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train LSTM model\n",
        "    history = lstm_model.fit(\n",
        "        X_train_reshaped, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val_reshaped, y_val),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Get LSTM predictions on training and validation data for hybrid models\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], 5, 12)\n",
        "    X_val_reshaped = X_val.reshape(X_val.shape[0], 5, 12)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], 5, 12)\n",
        "\n",
        "    lstm_train_preds = lstm_model.predict(X_train_reshaped).flatten()\n",
        "    lstm_val_preds = lstm_model.predict(X_val_reshaped).flatten()\n",
        "    lstm_test_preds = lstm_model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "    # Create features for hybrid models by combining original features with LSTM predictions\n",
        "    X_train_hybrid = np.column_stack((X_train, lstm_train_preds))\n",
        "    X_val_hybrid = np.column_stack((X_val, lstm_val_preds))\n",
        "    X_test_hybrid = np.column_stack((X_test, lstm_test_preds))\n",
        "\n",
        "    # Initialize models\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Hybrid model: LSTM + RF\n",
        "    lstm_rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    lstm_rf_model.fit(X_train_hybrid, y_train)\n",
        "\n",
        "    # Hybrid model: LSTM + XGBoost\n",
        "    lstm_xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
        "    lstm_xgb_model.fit(X_train_hybrid, y_train)\n",
        "\n",
        "    # Train standalone models\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    gb_model.fit(X_train, y_train)\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "\n",
        "    return {\n",
        "        'lstm': lstm_model,\n",
        "        'rf': rf_model,\n",
        "        'gb': gb_model,\n",
        "        'xgb': xgb_model,\n",
        "        'lstm_rf': lstm_rf_model,\n",
        "        'lstm_xgb': lstm_xgb_model\n",
        "    }, X_test_reshaped, X_test_hybrid\n",
        "\n",
        "# 5. Evaluate models\n",
        "def evaluate_models(models, X_test, X_test_reshaped, X_test_hybrid, y_test):\n",
        "    results = {}\n",
        "\n",
        "    # Evaluate LSTM\n",
        "    lstm_preds = models['lstm'].predict(X_test_reshaped).flatten()\n",
        "    results['LSTM'] = {\n",
        "        'predictions': lstm_preds,\n",
        "        'mae': mean_absolute_error(y_test, lstm_preds),\n",
        "        'mse': mean_squared_error(y_test, lstm_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, lstm_preds)),\n",
        "        'r2': r2_score(y_test, lstm_preds)\n",
        "    }\n",
        "\n",
        "    # Evaluate Random Forest\n",
        "    rf_preds = models['rf'].predict(X_test)\n",
        "    results['Random Forest'] = {\n",
        "        'predictions': rf_preds,\n",
        "        'mae': mean_absolute_error(y_test, rf_preds),\n",
        "        'mse': mean_squared_error(y_test, rf_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, rf_preds)),\n",
        "        'r2': r2_score(y_test, rf_preds)\n",
        "    }\n",
        "\n",
        "    # Evaluate Gradient Boosting\n",
        "    gb_preds = models['gb'].predict(X_test)\n",
        "    results['Gradient Boosting'] = {\n",
        "        'predictions': gb_preds,\n",
        "        'mae': mean_absolute_error(y_test, gb_preds),\n",
        "        'mse': mean_squared_error(y_test, gb_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, gb_preds)),\n",
        "        'r2': r2_score(y_test, gb_preds)\n",
        "    }\n",
        "\n",
        "    # Evaluate XGBoost\n",
        "    xgb_preds = models['xgb'].predict(X_test)\n",
        "    results['XGBoost'] = {\n",
        "        'predictions': xgb_preds,\n",
        "        'mae': mean_absolute_error(y_test, xgb_preds),\n",
        "        'mse': mean_squared_error(y_test, xgb_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, xgb_preds)),\n",
        "        'r2': r2_score(y_test, xgb_preds)\n",
        "    }\n",
        "\n",
        "    # Evaluate LSTM + RF\n",
        "    lstm_rf_preds = models['lstm_rf'].predict(X_test_hybrid)\n",
        "    results['LSTM + RF'] = {\n",
        "        'predictions': lstm_rf_preds,\n",
        "        'mae': mean_absolute_error(y_test, lstm_rf_preds),\n",
        "        'mse': mean_squared_error(y_test, lstm_rf_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, lstm_rf_preds)),\n",
        "        'r2': r2_score(y_test, lstm_rf_preds)\n",
        "    }\n",
        "\n",
        "    # Evaluate LSTM + XGBoost\n",
        "    lstm_xgb_preds = models['lstm_xgb'].predict(X_test_hybrid)\n",
        "    results['LSTM + XGBoost'] = {\n",
        "        'predictions': lstm_xgb_preds,\n",
        "        'mae': mean_absolute_error(y_test, lstm_xgb_preds),\n",
        "        'mse': mean_squared_error(y_test, lstm_xgb_preds),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_test, lstm_xgb_preds)),\n",
        "        'r2': r2_score(y_test, lstm_xgb_preds)\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 6. Forecast for future years (2016-2030)\n",
        "def forecast_future(data, models, n_steps=5, future_years=15):\n",
        "    # Extract the last n_steps years of data for prediction\n",
        "    last_years = data.iloc[-n_steps:].copy()\n",
        "\n",
        "    # Create predictions for future years\n",
        "    future_predictions = {}\n",
        "    for model_name in ['Random Forest', 'Gradient Boosting', 'LSTM + RF', 'LSTM + XGBoost']:\n",
        "        future_predictions[model_name] = []\n",
        "\n",
        "    # Current last year\n",
        "    last_year = data['YEAR'].iloc[-1]\n",
        "\n",
        "    for i in range(future_years):\n",
        "        future_year = last_year + i + 1\n",
        "\n",
        "        # Use the last n_steps years to predict\n",
        "        last_sequence = last_years.iloc[:, 1:13].values.flatten()\n",
        "\n",
        "        # Make predictions with each model\n",
        "        # Random Forest\n",
        "        rf_pred = models['rf'].predict([last_sequence])[0]\n",
        "        future_predictions['Random Forest'].append(rf_pred)\n",
        "\n",
        "        # Gradient Boosting\n",
        "        gb_pred = models['gb'].predict([last_sequence])[0]\n",
        "        future_predictions['Gradient Boosting'].append(gb_pred)\n",
        "\n",
        "        # LSTM prediction\n",
        "        lstm_sequence = last_sequence.reshape(1, n_steps, 12)\n",
        "        lstm_pred = models['lstm'].predict(lstm_sequence)[0][0]\n",
        "\n",
        "        # Combine LSTM prediction with original features for hybrid models\n",
        "        hybrid_features = np.append(last_sequence, lstm_pred)\n",
        "\n",
        "        # LSTM + RF\n",
        "        lstm_rf_pred = models['lstm_rf'].predict([hybrid_features])[0]\n",
        "        future_predictions['LSTM + RF'].append(lstm_rf_pred)\n",
        "\n",
        "        # LSTM + XGBoost\n",
        "        lstm_xgb_pred = models['lstm_xgb'].predict([hybrid_features])[0]\n",
        "        future_predictions['LSTM + XGBoost'].append(lstm_xgb_pred)\n",
        "\n",
        "        # Update the last years data by removing the oldest year and adding a placeholder for the newest\n",
        "        # This is an approximation - in real scenarios this would be more complex\n",
        "        new_year_data = last_years.iloc[1:].copy()\n",
        "        new_row = pd.DataFrame({\n",
        "            'YEAR': [future_year],\n",
        "            'JAN': [last_years['JAN'].mean()],\n",
        "            'FEB': [last_years['FEB'].mean()],\n",
        "            'MAR': [last_years['MAR'].mean()],\n",
        "            'APR': [last_years['APR'].mean()],\n",
        "            'MAY': [last_years['MAY'].mean()],\n",
        "            'JUN': [last_years['JUN'].mean()],\n",
        "            'JUL': [last_years['JUL'].mean()],\n",
        "            'AUG': [last_years['AUG'].mean()],\n",
        "            'SEP': [last_years['SEP'].mean()],\n",
        "            'OCT': [last_years['OCT'].mean()],\n",
        "            'NOV': [last_years['NOV'].mean()],\n",
        "            'DEC': [last_years['DEC'].mean()],\n",
        "            'ANNUAL': [rf_pred]  # Using the RF prediction as an approximation\n",
        "        })\n",
        "        last_years = pd.concat([new_year_data, new_row], ignore_index=True)\n",
        "\n",
        "    # Create a DataFrame with future predictions\n",
        "    future_df = pd.DataFrame({\n",
        "        'YEAR': range(last_year + 1, last_year + future_years + 1),\n",
        "        'Random Forest': future_predictions['Random Forest'],\n",
        "        'Gradient Boosting': future_predictions['Gradient Boosting'],\n",
        "        'LSTM + RF': future_predictions['LSTM + RF'],\n",
        "        'LSTM + XGBoost': future_predictions['LSTM + XGBoost']\n",
        "    })\n",
        "\n",
        "    return future_df\n",
        "\n",
        "# 7. Visualize results\n",
        "def visualize_results(data, results, future_df, test_years, y_test):\n",
        "    # FIX: Get actual test years from the predictions length\n",
        "    actual_test_years = test_years[-len(results['Random Forest']['predictions']):]\n",
        "\n",
        "    # 1. Plot model performance metrics\n",
        "    metrics = ['mae', 'mse', 'rmse', 'r2']\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        metric_values = [results[model][metric] for model in ['Random Forest', 'Gradient Boosting', 'LSTM + RF', 'LSTM + XGBoost']]\n",
        "        ax = axes[i]\n",
        "        bars = ax.bar(['Random Forest', 'Gradient Boosting', 'LSTM + RF', 'LSTM + XGBoost'], metric_values)\n",
        "        ax.set_title(f'{metric.upper()} Comparison', fontsize=16)\n",
        "        ax.set_ylabel(metric.upper())\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Add values on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_performance_metrics.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Plot actual vs predicted rainfall for each model (2001-2015)\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    models_to_plot = ['Random Forest', 'Gradient Boosting', 'LSTM + RF', 'LSTM + XGBoost']\n",
        "\n",
        "    # Get the actual test values that match prediction length\n",
        "    y_test_adjusted = y_test[-len(results['Random Forest']['predictions']):]\n",
        "\n",
        "    for i, model_name in enumerate(models_to_plot):\n",
        "        ax = axes[i]\n",
        "        ax.plot(actual_test_years, results[model_name]['predictions'], marker='o', label=f'{model_name} Predicted')\n",
        "        ax.plot(actual_test_years, y_test_adjusted, marker='x', linestyle='--', label='Actual')\n",
        "        ax.set_title(f'{model_name}: Actual vs Predicted Rainfall (2001-2015)', fontsize=16)\n",
        "        ax.set_xlabel('Year')\n",
        "        ax.set_ylabel('Annual Rainfall (mm)')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('actual_vs_predicted_2001_2015.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Plot future predictions (2016-2030)\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for model_name in models_to_plot:\n",
        "        plt.plot(future_df['YEAR'], future_df[model_name], marker='o', label=model_name)\n",
        "\n",
        "    plt.title('Rainfall Predictions (2016-2030)', fontsize=18)\n",
        "    plt.xlabel('Year', fontsize=14)\n",
        "    plt.ylabel('Annual Rainfall (mm)', fontsize=14)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('future_predictions_2016_2030.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 4. Combined historical and future predictions plot\n",
        "    # Extract the actual values for years 2001-2015\n",
        "    historical_years = actual_test_years\n",
        "    historical_actual = y_test_adjusted\n",
        "\n",
        "    # Create the future years\n",
        "    future_years = future_df['YEAR'].values\n",
        "\n",
        "    plt.figure(figsize=(18, 10))\n",
        "\n",
        "    # Plot historical actual values\n",
        "    plt.plot(historical_years, historical_actual, 'k-', marker='o', linewidth=2, label='Actual (2001-2015)')\n",
        "\n",
        "    # Plot historical predictions for each model\n",
        "    for model_name in models_to_plot:\n",
        "        historical_pred = results[model_name]['predictions']\n",
        "        plt.plot(historical_years, historical_pred, linestyle='--', marker='x', alpha=0.7, label=f'{model_name} (2001-2015)')\n",
        "\n",
        "    # Add a vertical line to separate historical and future\n",
        "    plt.axvline(x=historical_years[-1], color='r', linestyle='--', alpha=0.5)\n",
        "    plt.text(historical_years[-1] + 0.5, plt.ylim()[0] + 0.9*(plt.ylim()[1] - plt.ylim()[0]), 'Predictions Start',\n",
        "             rotation=90, color='r')\n",
        "\n",
        "    # Plot future predictions for each model\n",
        "    for model_name in models_to_plot:\n",
        "        future_pred = future_df[model_name].values\n",
        "        plt.plot(future_years, future_pred, linestyle='-', marker='o', label=f'{model_name} (2016-2030)')\n",
        "\n",
        "    plt.title('Historical vs Future Rainfall Predictions for Tamil Nadu', fontsize=20)\n",
        "    plt.xlabel('Year', fontsize=16)\n",
        "    plt.ylabel('Annual Rainfall (mm)', fontsize=16)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3, fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('historical_and_future_predictions.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    return\n",
        "\n",
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Define file path\n",
        "    file_path = \"/content/drive/MyDrive/rainfall in india 1901-2015.csv\"\n",
        "\n",
        "    # Load and preprocess data\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    data = load_and_preprocess_data(file_path)\n",
        "\n",
        "    # Split data into training (1901-2000) and testing (2001-2015)\n",
        "    train_data = data[data['YEAR'] <= 2000]\n",
        "    test_data = data[data['YEAR'] > 2000]\n",
        "\n",
        "    # Get the test years for plotting\n",
        "    test_years = test_data['YEAR'].values\n",
        "\n",
        "    # Prepare time series data\n",
        "    n_steps = 5\n",
        "\n",
        "    # Prepare training data\n",
        "    X_train_val, y_train_val = prepare_time_series_data(train_data, n_steps)\n",
        "    X_test, y_test = prepare_time_series_data(test_data, n_steps)\n",
        "\n",
        "    # Further split training data into training and validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train models\n",
        "    print(\"Training models...\")\n",
        "    models, X_test_reshaped, X_test_hybrid = train_models(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "    # Evaluate models\n",
        "    print(\"Evaluating models...\")\n",
        "    results = evaluate_models(models, X_test, X_test_reshaped, X_test_hybrid, y_test)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"\\nModel Evaluation Metrics:\")\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  MAE: {metrics['mae']:.4f}\")\n",
        "        print(f\"  MSE: {metrics['mse']:.4f}\")\n",
        "        print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
        "        print(f\"  R²: {metrics['r2']:.4f}\")\n",
        "\n",
        "    # Find the best model based on RMSE\n",
        "    best_model = min(results.items(), key=lambda x: x[1]['rmse'])[0]\n",
        "    print(f\"\\nBest model based on RMSE: {best_model}\")\n",
        "\n",
        "    # Forecast future rainfall (2016-2030)\n",
        "    print(\"\\nForecasting future rainfall (2016-2030)...\")\n",
        "    future_df = forecast_future(data, models, n_steps=n_steps, future_years=15)\n",
        "\n",
        "    # Print future predictions\n",
        "    print(\"\\nFuture Rainfall Predictions (2016-2030):\")\n",
        "    print(future_df)\n",
        "\n",
        "    # Visualize results\n",
        "    print(\"\\nVisualizing results...\")\n",
        "    # Pass y_test as an additional parameter to ensure correct shapes\n",
        "    visualize_results(data, results, future_df, test_years, y_test)\n",
        "\n",
        "    print(\"\\nAnalysis complete! Check the generated visualizations for insights.\")"
      ]
    }
  ]
}